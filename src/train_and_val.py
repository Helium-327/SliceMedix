# -*- coding: UTF-8 -*-
'''
================================================
*      CREATE ON: 2024/12/30 14:07:28
*      AUTHOR: @Junyin Xiong
*      DESCRIPTION: è®­ç»ƒå’ŒéªŒè¯
=================================================
'''

from tqdm import tqdm
from torch.amp import GradScaler, autocast
import torch
import numpy as np


def train_one_epoch(model, train_loader, optimizer, loss_func, scaler, device):
    """
    è®­ç»ƒä¸€ä¸ªepoch
    :param model: æ¨¡å‹
    :param train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
    :param optimizer: ä¼˜åŒ–å™¨
    :param loss_func: æŸå¤±å‡½æ•°
    :param scaler: æ¢¯åº¦ç¼©æ”¾å™¨
    :param device: è®¾å¤‡
    :return: å¹³å‡æŸå¤±å€¼
    """
    model.train()

    total_loss, total_et_loss, total_tc_loss, total_wt_loss = 0.0, 0.0, 0.0, 0.0

    train_loader = tqdm(train_loader, desc="ğŸ› ï¸ -- Training", leave=False)

    for batch_idx, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        if labels.dim() == 4:
            labels = labels.squeeze(1).to(device)
        else:
            labels = labels.to(device)

        if torch.isnan(images).any() or torch.isinf(images).any():
            raise ValueError("Input tensor contains NaN or Inf values.")
        if torch.isnan(labels).any() or torch.isinf(labels).any():
            raise ValueError("Input tensor contains NaN or Inf values.")
        
        with autocast(device_type='cuda'):
            optimizer.zero_grad()

            predictions = model(images)
            if torch.isnan(predictions).any() or torch.isinf(predictions).any():
                raise ValueError("Input tensor contains NaN or Inf values.")
            mean_loss, et_loss, tc_loss, wt_loss = loss_func(predictions, labels)

            scaler.scale(mean_loss).backward()
            scaler.step(optimizer)
            scaler.update()

        total_loss += mean_loss.item()
        total_et_loss += et_loss.item()
        total_tc_loss += tc_loss.item()
        total_wt_loss += wt_loss.item()

    avg_loss = total_loss / len(train_loader)
    avg_et_loss = total_et_loss / len(train_loader)
    avg_tc_loss = total_tc_loss / len(train_loader)
    avg_wt_loss = total_wt_loss / len(train_loader)

    return avg_loss, avg_et_loss, avg_tc_loss, avg_wt_loss


def validate_one_epoch(model, metric, val_loader, loss_func, device):
    """
    éªŒè¯ä¸€ä¸ªepoch
    :param model: æ¨¡å‹
    :param metric: è¯„ä¼°æŒ‡æ ‡
    :param val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
    :param loss_func: æŸå¤±å‡½æ•°
    :param device: è®¾å¤‡
    :return: å¹³å‡æŸå¤±å€¼å’Œè¯„ä¼°æŒ‡æ ‡
    """
    metric_results = np.zeros((7, 4))
    model.eval()
    total_loss, total_et_loss, total_tc_loss, total_wt_loss = 0.0, 0.0, 0.0, 0.0

    with torch.no_grad():  # å…³é—­æ¢¯åº¦è®¡ç®—
        val_loader = tqdm(val_loader, desc="ğŸ§ -- Validating", leave=False)

        for batch_idx, (images, labels) in enumerate(val_loader):
            images, labels = images.to(device), labels.to(device)

            with autocast(device_type='cuda'):
                predictions = model(images)
                mean_loss, et_loss, tc_loss, wt_loss = loss_func(predictions, labels)
                batch_metrics = metric.update(predictions, labels)
                metric_results += batch_metrics

            total_loss += mean_loss.item()
            total_et_loss += et_loss.item()
            total_tc_loss += tc_loss.item()
            total_wt_loss += wt_loss.item()

    avg_loss = total_loss / len(val_loader)
    avg_et_loss = total_et_loss / len(val_loader)
    avg_tc_loss = total_tc_loss / len(val_loader)
    avg_wt_loss = total_wt_loss / len(val_loader)
    metric_results = metric_results / len(val_loader)

    return avg_loss, avg_et_loss, avg_tc_loss, avg_wt_loss, metric_results